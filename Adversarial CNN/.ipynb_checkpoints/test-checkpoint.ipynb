{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from torchvision import transforms, models\n",
    "from foolbox.attacks import L2ProjectedGradientDescentAttack\n",
    "from foolbox import PyTorchModel\n",
    "\n",
    "# in case CUDA is not available, shutdown notebook and reload GPU in terminal:\n",
    "#     sudo rmmod nvidia_uvm\n",
    "#     sudo modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "SEED_VALUE = 666\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set all seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitSeeds(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n",
    "\n",
    "InitSeeds(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop(IMG_SIZE, scale=(1.0, 1.0), ratio=(1.0, 1.1)),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network will be trained on cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "model.load_state_dict(torch.load(\"base model.pth\"))\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Network will be trained on {device} device\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network on original test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1404/1404 [00:31<00:00, 44.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8746 Acc: 0.7764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'AHE test/Dataset_test_64/'   \n",
    "test_dataset = torchvision.datasets.ImageFolder('img/'+test_dir, test_transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "phase = 'test'\n",
    "dataloader = test_dataloader\n",
    "\n",
    "running_loss = 0. \n",
    "running_acc = 0.\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    inputs = inputs.to(device) # Тензор с изображениями переводим на GPU \n",
    "    labels = labels.to(device) # Тензор с лейблами переводим на GPU \n",
    " \n",
    "    optimizer.zero_grad() # Обнуляем градиент,чтобы он не накапливался \n",
    " \n",
    "    with torch.set_grad_enabled(phase == 'train'): #Если фаза train то активируем все градиенты (те которые не заморожены) (очистить историю loss)\n",
    "        preds = model(inputs) # Считаем предикты, input передаем в модель\n",
    "        loss_value = loss_func(preds, labels) #Посчитали  Loss\n",
    "        preds_class = preds.argmax(dim=1) # Получаем класс,берем .argmax(dim=1) нейрон с максимальной активацией\n",
    "    # Статистика\n",
    "    running_loss += loss_value.item() #считаем Loss\n",
    "    running_acc += (preds_class == labels.data).float().mean().data.cpu().numpy()  #считаем accuracy\n",
    " \n",
    "epoch_loss = running_loss / len(dataloader)  # Loss'ы делим на кол-во бачей в эпохе \n",
    "epoch_acc = running_acc / len(dataloader) #считаем Loss на кол-во бачей в эпохе\n",
    " \n",
    "print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test network on attacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1404/1404 [51:52<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on attacked images: 0.774928774928775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate attacked images\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "    \n",
    "def UnNormalize(norm_img: torch.Tensor) -> torch.Tensor:\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).reshape(1,3,1,1).to(device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).reshape(1,3,1,1).to(device)\n",
    "    return norm_img*std + mean\n",
    "\n",
    "model_for_attacks = copy.deepcopy(model)\n",
    "for param in model_for_attacks.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "test_dataset = ImageFolderWithPaths('img/'+test_dir, test_transforms)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "fmodel = PyTorchModel(model, bounds=(0, 1))\n",
    "\n",
    "L2PGDattack = L2ProjectedGradientDescentAttack(steps = 50)\n",
    "\n",
    "success_count = 0\n",
    "\n",
    "for inputs, labels, paths in tqdm(test_dataloader):\n",
    "    #print(inputs, labels, paths)\n",
    "    inputs = inputs.to(device) # Тензор с изображениями переводим на GPU \n",
    "    labels = labels.to(device) # Тензор с лейблами переводим на GPU \n",
    "    _, bacth_adv, success = L2PGDattack(fmodel, inputs, labels, epsilons = [128/255])\n",
    "    img_adv = UnNormalize(bacth_adv[0])\n",
    "    #print(int(success[0][0]))\n",
    "    success_count += int(success[0][0])\n",
    "    #img_adv = bacth_adv[0]\n",
    "    #print(\"Generated adversarial image:\\n\", img_adv[0])\n",
    "    img_class = paths[0].split(\"/\")[-2]\n",
    "    img_name = paths[0].split(\"/\")[-1].rsplit(\".\", maxsplit = 1)[0] +\\\n",
    "               \"_attacked\" + \".\" +\\\n",
    "               paths[0].split(\"/\")[-1].rsplit(\".\", maxsplit = 1)[1]\n",
    "    img_path = os.path.join(\"img\", \"test attacked\", img_class, img_name)\n",
    "    os.makedirs(os.path.join('img', \"test attacked\", img_class), exist_ok = True)\n",
    "    torchvision.utils.save_image(img_adv[0], img_path)\n",
    "print(f\"Accuracy on attacked images: {1 - success_count/len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 702/702 [00:14<00:00, 49.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9228 Acc: 0.7610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on attacked images\n",
    "test_dir = 'test attacked'\n",
    "    \n",
    "test_dataset = torchvision.datasets.ImageFolder('img/'+test_dir, test_transforms)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=8)\n",
    "\n",
    "phase = 'test'\n",
    "dataloader = test_dataloader\n",
    "model.eval()\n",
    " \n",
    "running_loss = 0. \n",
    "running_acc = 0.\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    " \n",
    "# Итерируемся по dataloader\n",
    "for inputs, labels in tqdm(dataloader):\n",
    "    inputs = inputs.to(device) # Тензор с изображениями переводим на GPU \n",
    "    labels = labels.to(device) # Тензор с лейблами переводим на GPU \n",
    " \n",
    "    optimizer.zero_grad() # Обнуляем градиент,чтобы он не накапливался \n",
    " \n",
    "    with torch.set_grad_enabled(phase == 'train'): #Если фаза train то активируем все градиенты (те которые не заморожены) (очистить историю loss)\n",
    "        preds = model(inputs) # Считаем предикты, input передаем в модель\n",
    "        loss_value = loss_func(preds, labels) #Посчитали  Loss\n",
    "        preds_class = preds.argmax(dim=1) # Получаем класс,берем .argmax(dim=1) нейрон с максимальной активацией\n",
    "    # Статистика\n",
    "    running_loss += loss_value.item() #считаем Loss\n",
    "    running_acc += (preds_class == labels.data).float().mean().data.cpu().numpy()  #считаем accuracy\n",
    " \n",
    "epoch_loss = running_loss / len(dataloader)  # Loss'ы делим на кол-во бачей в эпохе \n",
    "epoch_acc = running_acc / len(dataloader) #считаем Loss на кол-во бачей в эпохе\n",
    " \n",
    "print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc), end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
